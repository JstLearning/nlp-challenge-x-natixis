{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from model_02.dataset import ReturnsDataset\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.preprocessing import ecb_pipeline_en, fast_detect\n",
    "\n",
    "import time\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"data/train_series.csv\"\n",
    "FILENAME_ECB = \"data/ecb_data.csv\"\n",
    "FILENAME_FED = \"data/fed_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.read_csv(FILENAME, index_col=0)\n",
    "ecb = pd.read_csv(FILENAME_ECB, index_col=0)\n",
    "fed = pd.read_csv(FILENAME_FED, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.get_dummies(returns, columns=[\"Index Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns[\"Sign\"] = (returns[\"Index + 1\"] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index - 9</th>\n",
       "      <th>Index - 8</th>\n",
       "      <th>Index - 7</th>\n",
       "      <th>Index - 6</th>\n",
       "      <th>Index - 5</th>\n",
       "      <th>Index - 4</th>\n",
       "      <th>Index - 3</th>\n",
       "      <th>Index - 2</th>\n",
       "      <th>Index - 1</th>\n",
       "      <th>Index - 0</th>\n",
       "      <th>...</th>\n",
       "      <th>Index Name_CVIX Index</th>\n",
       "      <th>Index Name_EURUSD Curncy</th>\n",
       "      <th>Index Name_EURUSDV1M Curncy</th>\n",
       "      <th>Index Name_MOVE Index</th>\n",
       "      <th>Index Name_SPX Index</th>\n",
       "      <th>Index Name_SRVIX Index</th>\n",
       "      <th>Index Name_SX5E Index</th>\n",
       "      <th>Index Name_V2X Index</th>\n",
       "      <th>Index Name_VIX Index</th>\n",
       "      <th>Sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>-0.027519</td>\n",
       "      <td>-0.103565</td>\n",
       "      <td>-0.045086</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.054050</td>\n",
       "      <td>0.015779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.021497</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>-0.013175</td>\n",
       "      <td>-0.008436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026303</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001872</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>0.023588</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.011304</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.001893</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>-0.003056</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>-0.006444</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index - 9  Index - 8  Index - 7  Index - 6  Index - 5  Index - 4  \\\n",
       "0   0.001045   0.005841   0.003832  -0.027519  -0.103565  -0.045086   \n",
       "1  -0.021497   0.007891  -0.013175  -0.008436   0.000000   0.026303   \n",
       "2  -0.001872  -0.008154   0.023588   0.004086   0.003493   0.003300   \n",
       "3   0.004980  -0.000864   0.001677   0.000000   0.006030  -0.001083   \n",
       "4   0.000360  -0.001893   0.005579  -0.003056  -0.001171  -0.001623   \n",
       "\n",
       "   Index - 3  Index - 2  Index - 1  Index - 0  ... Index Name_CVIX Index  \\\n",
       "0  -0.011265   0.005164   0.054050   0.015779  ...                     0   \n",
       "1   0.000556   0.001455   0.007422   0.000000  ...                     0   \n",
       "2   0.000885  -0.011304   0.005040   0.000156  ...                     0   \n",
       "3   0.000419   0.001492   0.001018  -0.002582  ...                     0   \n",
       "4  -0.002350  -0.006444  -0.000729  -0.000365  ...                     0   \n",
       "\n",
       "  Index Name_EURUSD Curncy  Index Name_EURUSDV1M Curncy  \\\n",
       "0                        0                            0   \n",
       "1                        0                            0   \n",
       "2                        0                            0   \n",
       "3                        0                            0   \n",
       "4                        1                            0   \n",
       "\n",
       "   Index Name_MOVE Index  Index Name_SPX Index  Index Name_SRVIX Index  \\\n",
       "0                      0                     0                       0   \n",
       "1                      1                     0                       0   \n",
       "2                      0                     1                       0   \n",
       "3                      0                     1                       0   \n",
       "4                      0                     0                       0   \n",
       "\n",
       "   Index Name_SX5E Index  Index Name_V2X Index  Index Name_VIX Index  Sign  \n",
       "0                      0                     1                     0     1  \n",
       "1                      0                     0                     0     1  \n",
       "2                      0                     0                     0     1  \n",
       "3                      0                     0                     0     1  \n",
       "4                      0                     0                     0     1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = returns[\"Sign\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4930\n",
       "1    4016\n",
       "Name: Sign, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = returns.drop([\"Sign\", \"Index + 1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index - 9', 'Index - 8', 'Index - 7', 'Index - 6', 'Index - 5',\n",
       "       'Index - 4', 'Index - 3', 'Index - 2', 'Index - 1', 'Index - 0',\n",
       "       'index ecb', 'index fed', 'Index Name_CVIX Index',\n",
       "       'Index Name_EURUSD Curncy', 'Index Name_EURUSDV1M Curncy',\n",
       "       'Index Name_MOVE Index', 'Index Name_SPX Index',\n",
       "       'Index Name_SRVIX Index', 'Index Name_SX5E Index',\n",
       "       'Index Name_V2X Index', 'Index Name_VIX Index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontextual_cols = ['Index - 9',\n",
    " 'Index - 8',\n",
    " 'Index - 7',\n",
    " 'Index - 6',\n",
    " 'Index - 5',\n",
    " 'Index - 4',\n",
    " 'Index - 3',\n",
    " 'Index - 2',\n",
    " 'Index - 1',\n",
    " 'Index - 0',\n",
    " 'Index Name_CVIX Index',\n",
    " 'Index Name_EURUSD Curncy',\n",
    " 'Index Name_EURUSDV1M Curncy',\n",
    " 'Index Name_MOVE Index',\n",
    " 'Index Name_SPX Index',\n",
    " 'Index Name_SRVIX Index',\n",
    " 'Index Name_SX5E Index',\n",
    " 'Index Name_V2X Index',\n",
    " 'Index Name_VIX Index']\n",
    "nb_nontextfeatures = len(nontextual_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% train, 20% val, 20% test\n",
    "\n",
    "returns_, returns_test, y_, y_test = train_test_split(\n",
    "    returns, y, test_size=0.2, train_size=0.8,\n",
    "    random_state=0, stratify=y\n",
    "    )\n",
    "\n",
    "returns_train, returns_val, y_train, y_val = train_test_split(\n",
    "    returns_, y_, test_size=0.25, train_size=0.75,\n",
    "    random_state=42, stratify=y_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del returns, y\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comments by Yves Mersch at Financial Services ...</td>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>Comments by Yves Mersch at Financial Service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Securing sustained economic growth in the euro...</td>\n",
       "      <td>VÃ­tor ConstÃ¢ncio</td>\n",
       "      <td>Securing sustained economic growth in the eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The role of monetary policy in addressing the ...</td>\n",
       "      <td>Mario Draghi</td>\n",
       "      <td>The role of monetary policy in addressing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pandemic emergency: the three challenges f...</td>\n",
       "      <td>Philip R. Lane</td>\n",
       "      <td>SPEECH  The pandemic emergency: the three c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transmission channels of monetary policy in th...</td>\n",
       "      <td>Peter Praet</td>\n",
       "      <td>Transmission channels of monetary policy in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           speaker  \\\n",
       "0  Comments by Yves Mersch at Financial Services ...       Yves Mersch   \n",
       "1  Securing sustained economic growth in the euro...  VÃ­tor ConstÃ¢ncio   \n",
       "2  The role of monetary policy in addressing the ...      Mario Draghi   \n",
       "3  The pandemic emergency: the three challenges f...    Philip R. Lane   \n",
       "4  Transmission channels of monetary policy in th...       Peter Praet   \n",
       "\n",
       "                                                text  \n",
       "0    Comments by Yves Mersch at Financial Service...  \n",
       "1    Securing sustained economic growth in the eu...  \n",
       "2    The role of monetary policy in addressing th...  \n",
       "3     SPEECH  The pandemic emergency: the three c...  \n",
       "4    Transmission channels of monetary policy in ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Importance of Economic Education and Finan...</td>\n",
       "      <td>Governor Frederic S. Mishkin</td>\n",
       "      <td>As ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financial Innovation and Consumer Protection</td>\n",
       "      <td>Chairman Ben S. Bernanke</td>\n",
       "      <td>The concept of financial innovation, it seems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Implementing Basel II in the United States</td>\n",
       "      <td>Governor Randall S. Kroszner</td>\n",
       "      <td>Good afternoon. I would like to thank Standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An Assessment of the U.S. Economy</td>\n",
       "      <td>Vice Chair for Supervision Randal K. Quarles</td>\n",
       "      <td>Thank you for the opportunity to take part in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monetary Policy since the Onset of the Crisis</td>\n",
       "      <td>Chairman Ben S. Bernanke</td>\n",
       "      <td>When we convened in Jackson Hole in August 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The Importance of Economic Education and Finan...   \n",
       "1       Financial Innovation and Consumer Protection   \n",
       "2         Implementing Basel II in the United States   \n",
       "3                  An Assessment of the U.S. Economy   \n",
       "4      Monetary Policy since the Onset of the Crisis   \n",
       "\n",
       "                                        speaker  \\\n",
       "0                  Governor Frederic S. Mishkin   \n",
       "1                      Chairman Ben S. Bernanke   \n",
       "2                  Governor Randall S. Kroszner   \n",
       "3  Vice Chair for Supervision Randal K. Quarles   \n",
       "4                      Chairman Ben S. Bernanke   \n",
       "\n",
       "                                                text  \n",
       "0                                             As ...  \n",
       "1   The concept of financial innovation, it seems...  \n",
       "2   Good afternoon. I would like to thank Standar...  \n",
       "3   Thank you for the opportunity to take part in...  \n",
       "4   When we convened in Jackson Hole in August 20...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecb[\"text_\"] = ecb.apply(ecb_pipeline_en, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecb[\"text\"].fillna(\"\", inplace=True)\n",
    "ecb[\"speaker\"].fillna(\"Unknown\", inplace=True)\n",
    "fed[\"speaker\"].fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                         Auf neuen Wegen zum alten Ziel\n",
       "speaker                                          Yves Mersch\n",
       "text         Auf neuen Wegen zum alten Ziel   Rede von Yv...\n",
       "text_      Rede von Yves Mersch, Mitglied des Direktorium...\n",
       "Name: 151, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text in french\n",
    "ecb.loc[138]\n",
    "# Text in german\n",
    "ecb.loc[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecb[\"lang\"] = ecb[\"text_\"].apply(fast_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comments by Yves Mersch at Financial Services ...</td>\n",
       "      <td>Yves Mersch</td>\n",
       "      <td>Comments by Yves Mersch at Financial Service...</td>\n",
       "      <td>Sustainable economic growth in the real econom...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Securing sustained economic growth in the euro...</td>\n",
       "      <td>VÃ­tor ConstÃ¢ncio</td>\n",
       "      <td>Securing sustained economic growth in the eu...</td>\n",
       "      <td>Ladies and Gentlemen, Thank you for inviting m...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The role of monetary policy in addressing the ...</td>\n",
       "      <td>Mario Draghi</td>\n",
       "      <td>The role of monetary policy in addressing th...</td>\n",
       "      <td>There was a time, not too long ago, when centr...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pandemic emergency: the three challenges f...</td>\n",
       "      <td>Philip R. Lane</td>\n",
       "      <td>SPEECH  The pandemic emergency: the three c...</td>\n",
       "      <td>Today, I will discuss the monetary policy meas...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transmission channels of monetary policy in th...</td>\n",
       "      <td>Peter Praet</td>\n",
       "      <td>Transmission channels of monetary policy in ...</td>\n",
       "      <td>Ladies and Gentlemen, Since the onset of the f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           speaker  \\\n",
       "0  Comments by Yves Mersch at Financial Services ...       Yves Mersch   \n",
       "1  Securing sustained economic growth in the euro...  VÃ­tor ConstÃ¢ncio   \n",
       "2  The role of monetary policy in addressing the ...      Mario Draghi   \n",
       "3  The pandemic emergency: the three challenges f...    Philip R. Lane   \n",
       "4  Transmission channels of monetary policy in th...       Peter Praet   \n",
       "\n",
       "                                                text  \\\n",
       "0    Comments by Yves Mersch at Financial Service...   \n",
       "1    Securing sustained economic growth in the eu...   \n",
       "2    The role of monetary policy in addressing th...   \n",
       "3     SPEECH  The pandemic emergency: the three c...   \n",
       "4    Transmission channels of monetary policy in ...   \n",
       "\n",
       "                                               text_ lang  \n",
       "0  Sustainable economic growth in the real econom...   en  \n",
       "1  Ladies and Gentlemen, Thank you for inviting m...   en  \n",
       "2  There was a time, not too long ago, when centr...   en  \n",
       "3  Today, I will discuss the monetary policy meas...   en  \n",
       "4  Ladies and Gentlemen, Since the onset of the f...   en  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed[\"lang\"] = fed[\"text\"].apply(fast_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Importance of Economic Education and Finan...</td>\n",
       "      <td>Governor Frederic S. Mishkin</td>\n",
       "      <td>As ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financial Innovation and Consumer Protection</td>\n",
       "      <td>Chairman Ben S. Bernanke</td>\n",
       "      <td>The concept of financial innovation, it seems...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Implementing Basel II in the United States</td>\n",
       "      <td>Governor Randall S. Kroszner</td>\n",
       "      <td>Good afternoon. I would like to thank Standar...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An Assessment of the U.S. Economy</td>\n",
       "      <td>Vice Chair for Supervision Randal K. Quarles</td>\n",
       "      <td>Thank you for the opportunity to take part in...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monetary Policy since the Onset of the Crisis</td>\n",
       "      <td>Chairman Ben S. Bernanke</td>\n",
       "      <td>When we convened in Jackson Hole in August 20...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The Importance of Economic Education and Finan...   \n",
       "1       Financial Innovation and Consumer Protection   \n",
       "2         Implementing Basel II in the United States   \n",
       "3                  An Assessment of the U.S. Economy   \n",
       "4      Monetary Policy since the Onset of the Crisis   \n",
       "\n",
       "                                        speaker  \\\n",
       "0                  Governor Frederic S. Mishkin   \n",
       "1                      Chairman Ben S. Bernanke   \n",
       "2                  Governor Randall S. Kroszner   \n",
       "3  Vice Chair for Supervision Randal K. Quarles   \n",
       "4                      Chairman Ben S. Bernanke   \n",
       "\n",
       "                                                text lang  \n",
       "0                                             As ...   en  \n",
       "1   The concept of financial innovation, it seems...   en  \n",
       "2   Good afternoon. I would like to thank Standar...   en  \n",
       "3   Thank you for the opportunity to take part in...   en  \n",
       "4   When we convened in Jackson Hole in August 20...   en  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_langs = ecb[\"lang\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    1646\n",
       "de      75\n",
       "fr      31\n",
       "es      16\n",
       "it       4\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecb[\"lang\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Importance of Economic Education and Finan...</td>\n",
       "      <td>Governor Frederic S. Mishkin</td>\n",
       "      <td>As ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financial Innovation and Consumer Protection</td>\n",
       "      <td>Chairman Ben S. Bernanke</td>\n",
       "      <td>The concept of financial innovation, it seems...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Implementing Basel II in the United States</td>\n",
       "      <td>Governor Randall S. Kroszner</td>\n",
       "      <td>Good afternoon. I would like to thank Standar...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An Assessment of the U.S. Economy</td>\n",
       "      <td>Vice Chair for Supervision Randal K. Quarles</td>\n",
       "      <td>Thank you for the opportunity to take part in...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monetary Policy since the Onset of the Crisis</td>\n",
       "      <td>Chairman Ben S. Bernanke</td>\n",
       "      <td>When we convened in Jackson Hole in August 20...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The Importance of Economic Education and Finan...   \n",
       "1       Financial Innovation and Consumer Protection   \n",
       "2         Implementing Basel II in the United States   \n",
       "3                  An Assessment of the U.S. Economy   \n",
       "4      Monetary Policy since the Onset of the Crisis   \n",
       "\n",
       "                                        speaker  \\\n",
       "0                  Governor Frederic S. Mishkin   \n",
       "1                      Chairman Ben S. Bernanke   \n",
       "2                  Governor Randall S. Kroszner   \n",
       "3  Vice Chair for Supervision Randal K. Quarles   \n",
       "4                      Chairman Ben S. Bernanke   \n",
       "\n",
       "                                                text lang  \n",
       "0                                             As ...   en  \n",
       "1   The concept of financial innovation, it seems...   en  \n",
       "2   Good afternoon. I would like to thank Standar...   en  \n",
       "3   Thank you for the opportunity to take part in...   en  \n",
       "4   When we convened in Jackson Hole in August 20...   en  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "max_corpus_len = 2\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "    X_ecb = []\n",
    "    X_fed = []\n",
    "    X_ind = []\n",
    "    y = []\n",
    "    \n",
    "    for data in batch:\n",
    "        X_ecb.extend(data[0][0])\n",
    "        X_fed.extend(data[0][1])\n",
    "        X_ind.append(data[0][2])\n",
    "        y.append(data[1])\n",
    "\n",
    "    # tic = time.perf_counter()\n",
    "    X_ecb_tokens = tokenizer(X_ecb, return_tensors=\"pt\",\n",
    "                      truncation=True, padding='max_length', max_length=512)\n",
    "    X_ecb = X_ecb_tokens['input_ids'].view(batch_size, max_corpus_len, 512)\n",
    "    X_ecb_att = X_ecb_tokens['attention_mask'].view(batch_size, max_corpus_len, 512)\n",
    "\n",
    "    X_fed_tokens = tokenizer(X_fed, return_tensors=\"pt\",\n",
    "                      truncation=True, padding='max_length', max_length=512)\n",
    "    X_fed = X_fed_tokens['input_ids'].view(batch_size, max_corpus_len, 512)\n",
    "    X_fed_att = X_fed_tokens['attention_mask'].view(batch_size, max_corpus_len, 512)\n",
    "    # toc = time.perf_counter()\n",
    "    # print(f\"1 batch tokenized in {toc - tic:0.4f} seconds\")\n",
    "    X_ind = torch.stack(X_ind, dim=0)\n",
    "    \n",
    "    return {\n",
    "        \"X_ecb\": X_ecb,\n",
    "        \"X_ecb mask\": X_ecb_att,\n",
    "        \"X_fed\": X_fed,\n",
    "        \"X_fed_mask\": X_fed_att,\n",
    "        \"X_ind\": X_ind,\n",
    "        \"label\": torch.Tensor(y)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=ReturnsDataset(returns_train, ecb, fed, y_train),\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=2,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=ReturnsDataset(returns_val, ecb, fed, y_val),\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=ReturnsDataset(returns_test, ecb, fed, y_test),\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_02.model import MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (corpus_enc_ecb): CorpusEncoder(\n",
       "    (doc_encoder): DocumentEncoder(\n",
       "      (text_encoder): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (1): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (2): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (3): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (4): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (5): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (att_bigru): AttentionBiGRU(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (bigru): GRU(768, 64, batch_first=True, bidirectional=True)\n",
       "        (attention): AttentionWithContext(\n",
       "          (W): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tanh): Tanh()\n",
       "          (u): Linear(in_features=128, out_features=1, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (att_bigru): AttentionBiGRU(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (bigru): GRU(32, 8, batch_first=True, bidirectional=True)\n",
       "      (attention): AttentionWithContext(\n",
       "        (W): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (tanh): Tanh()\n",
       "        (u): Linear(in_features=16, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (corpus_enc_fed): CorpusEncoder(\n",
       "    (doc_encoder): DocumentEncoder(\n",
       "      (text_encoder): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (1): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (2): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (3): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (4): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (5): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (att_bigru): AttentionBiGRU(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (bigru): GRU(768, 64, batch_first=True, bidirectional=True)\n",
       "        (attention): AttentionWithContext(\n",
       "          (W): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tanh): Tanh()\n",
       "          (u): Linear(in_features=128, out_features=1, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (att_bigru): AttentionBiGRU(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (bigru): GRU(32, 8, batch_first=True, bidirectional=True)\n",
       "      (attention): AttentionWithContext(\n",
       "        (W): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (tanh): Tanh()\n",
       "        (u): Linear(in_features=16, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=51, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(dropout=1/2).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  101,  6203, 11141,  ...,  1996,  3072,   102],\n",
      "         [  101,   102,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[  101,  6203,  6456,  ...,  1996,  4132,   102],\n",
      "         [  101,  6203,  6456,  ...,  2013,  3032,   102]],\n",
      "\n",
      "        [[  101,  2048,  2350,  ...,  1012,  1999,   102],\n",
      "         [  101,   102,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  101,  1006,  1529,  ...,  2197,  2416,   102],\n",
      "         [  101,   102,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[  101,  2009,  2003,  ...,  2000,  7868,   102],\n",
      "         [  101,   102,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[  101, 12194,  3343,  ...,  2008,  2057,   102],\n",
      "         [  101,   102,     0,  ...,     0,     0,     0]]], device='cuda:0')\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 0, 0, 0]]], device='cuda:0')\n",
      "tensor([[0.5477],\n",
      "        [0.5478],\n",
      "        [0.5529],\n",
      "        [0.5553],\n",
      "        [0.5546],\n",
      "        [0.5505],\n",
      "        [0.5548],\n",
      "        [0.5474],\n",
      "        [0.5426],\n",
      "        [0.5493],\n",
      "        [0.5496],\n",
      "        [0.5519],\n",
      "        [0.5534],\n",
      "        [0.5493],\n",
      "        [0.5453],\n",
      "        [0.5555],\n",
      "        [0.5424],\n",
      "        [0.5489],\n",
      "        [0.5512],\n",
      "        [0.5470],\n",
      "        [0.5553],\n",
      "        [0.5545],\n",
      "        [0.5574],\n",
      "        [0.5464],\n",
      "        [0.5400],\n",
      "        [0.5535],\n",
      "        [0.5409],\n",
      "        [0.5482],\n",
      "        [0.5487],\n",
      "        [0.5489],\n",
      "        [0.5534],\n",
      "        [0.5452]], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Test output\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    X_ecb = batch[\"X_ecb\"].to(device)\n",
    "    X_ecb_att = batch[\"X_ecb mask\"].to(device)\n",
    "    X_fed = batch[\"X_fed\"].to(device)\n",
    "    X_fed_att = batch[\"X_fed_mask\"].to(device)\n",
    "    X_ind =  batch[\"X_ind\"].to(device)\n",
    "    y = batch[\"label\"]\n",
    "    output = model(X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind)\n",
    "print(X_ecb)\n",
    "print(X_ecb_att)\n",
    "print(output)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "decay = 1e-5\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "epoch = 1\n",
    "model.load_state_dict(torch.load(f\"model_02/weights/model_bis_{epoch}_epoch.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2684/2684 [57:26<00:00,  1.28s/batch, accuracy=53, loss=0.69]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over the last epoch: 0.6904\n",
      "Accuracy over the last epoch: 0.5303\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "eval_every = 5\n",
    "\n",
    "model.train()\n",
    "for epoch_ in range(1, epochs+1):\n",
    "    model.train()\n",
    "    print(\"Epoch \", epoch+epoch_)\n",
    "    total_loss = 0\n",
    "    total_entries = 0\n",
    "    correct = 0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+epoch_}\")\n",
    "            optimizer.zero_grad()\n",
    "            X_ecb = batch[\"X_ecb\"].to(device)\n",
    "            X_ecb_att = batch[\"X_ecb mask\"].to(device)\n",
    "            X_fed = batch[\"X_fed\"].to(device)\n",
    "            X_fed_att = batch[\"X_fed_mask\"].to(device)\n",
    "            X_ind =  batch[\"X_ind\"].to(device)\n",
    "            y = batch[\"label\"].to(device)\n",
    "            batch_size_ = y.size(0)\n",
    "            output = model(X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind).view(-1)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            output = (output > 1/2).float()\n",
    "            correct += (output == y).sum().item()\n",
    "            total_loss += loss.item() * batch_size_\n",
    "            total_entries += batch_size_\n",
    "\n",
    "            # del X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind, y, batch\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            tepoch.set_postfix(loss=total_loss/total_entries, accuracy=100. * correct/total_entries)\n",
    "\n",
    "    print(f\"Mean loss over the last epoch: {total_loss / total_entries:.4f}\")\n",
    "    print(f\"Accuracy over the last epoch: {correct / total_entries:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"model_01/weights/model_bis_{epoch+epoch_}_epoch.pt\")\n",
    "    if not eval_every is None and epoch+epoch_ > 1 and epoch+epoch_%eval_every == 0:\n",
    "        model.eval()\n",
    "        print(f\"Evaluation at epoch {epoch+epoch_}\")\n",
    "        total_loss = 0\n",
    "        total_entries = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "\n",
    "                X_ecb = batch[\"X_ecb\"].to(device)\n",
    "                X_ecb_att = batch[\"X_ecb mask\"].to(device)\n",
    "                X_fed = batch[\"X_fed\"].to(device)\n",
    "                X_fed_att = batch[\"X_fed_mask\"].to(device)\n",
    "                X_ind =  batch[\"X_ind\"].to(device)\n",
    "                y = batch[\"label\"].to(device)\n",
    "                batch_size_ = y.size(0)\n",
    "                output = model(X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind).view(-1)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                total_loss += loss.item() * batch_size_\n",
    "                output = (output > 1/2).float()\n",
    "                correct += (output == y).sum().item()\n",
    "                total_entries += batch_size_\n",
    "\n",
    "                del X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind, batch\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            print(f\"Mean loss over validation set: {total_loss / total_entries:.4f}\")\n",
    "            print(f\"Accuracy over validation set: {correct / total_entries:.4f}\")\n",
    "epoch += epoch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [10:39<00:00, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over validation set: 0.6872\n",
      "Accuracy over validation set: 0.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(f\"Evaluation at epoch {epoch}\")\n",
    "total_loss = 0\n",
    "total_entries = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "\n",
    "        X_ecb = batch[\"X_ecb\"].to(device)\n",
    "        X_ecb_att = batch[\"X_ecb mask\"].to(device)\n",
    "        X_fed = batch[\"X_fed\"].to(device)\n",
    "        X_fed_att = batch[\"X_fed_mask\"].to(device)\n",
    "        X_ind =  batch[\"X_ind\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "        batch_size_ = y.size(0)\n",
    "        output = model(X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind).view(-1)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        total_loss += loss.item() * batch_size_\n",
    "        output = (output > 1/2).float()\n",
    "        correct += (output == y).sum().item()\n",
    "        total_entries += batch_size_\n",
    "\n",
    "        del X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind, batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "print(f\"Mean loss over validation set: {total_loss / total_entries:.4f}\")\n",
    "print(f\"Accuracy over validation set: {correct / total_entries:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [10:52<00:00, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss over test set: 0.6872\n",
      "Accuracy over test set: 0.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(f\"Test at epoch {epoch}\")\n",
    "total_loss = 0\n",
    "total_entries = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "\n",
    "        X_ecb = batch[\"X_ecb\"].to(device)\n",
    "        X_ecb_att = batch[\"X_ecb mask\"].to(device)\n",
    "        X_fed = batch[\"X_fed\"].to(device)\n",
    "        X_fed_att = batch[\"X_fed_mask\"].to(device)\n",
    "        X_ind =  batch[\"X_ind\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "        batch_size_ = y.size(0)\n",
    "        output = model(X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind).view(-1)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        total_loss += loss.item() * batch_size_\n",
    "        output = (output > 1/2).float()\n",
    "        correct += (output == y).sum().item()\n",
    "        total_entries += batch_size_\n",
    "\n",
    "        del X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind, batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "print(f\"Mean loss over test set: {total_loss / total_entries:.4f}\")\n",
    "print(f\"Accuracy over test set: {correct / total_entries:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model_01/weights/model_{epoch}_epoch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_ecb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3332\\3915344007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mX_ecb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_ecb_att\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fed_att\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_ecb' is not defined"
     ]
    }
   ],
   "source": [
    "del X_ecb, X_ecb_att, X_fed, X_fed_att, X_ind, batch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a4c350da27618d5732fc58ebcab8d2c0381c51b7361f332741f21e30512bbdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
